# Configurations for model training
dataset: 'ITOP-SIDE'
device_args: 6
wandb_active: false
seed: 0
model: 'P4Transformer'
wandb_project: 'hpe'
mode_train: true
mode_val: true
use_valid_only: true


# input
clip_len: 7
frame_interval: 1
max_frame_interval: 20
num_points: 4096


#threshold
threshold: 0.1

# P4D
radius: 0.7
nsamples: 32
spatial_stride: 32
temporal_kernel_size: 3
temporal_stride: 1
# embedding
emb_relu: false
# transformer
dim: 1024
depth: 5
heads: 8
dim_head: 256
mlp_dim: 2048
dropout1: 0.0
dropout2: 0.0



# training
batch_size: 24
epochs: 100
workers: 8
lr: 0.01
momentum: 0.9
weight_decay: 1e-4
lr_milestones:
  - 20
  - 30
lr_gamma: 1.0
lr_warmup_epochs: 0
# output
log_dir: "log"
    # resume
resume: ''
start_epoch: 0
    # losses
loss_type: 'l1'   # choices=['std_cross_entropy', 'weighted_cross_entropy', 'focal'],
save: True

DS_AUGMENTS_CFG: null