# Configurations for model training
bad_train: 'BAD1'
bad_test: 'BAD1'
device_args: 5
wandb_active: false
seed: 0
model: 'P4Transformer'
# input
clip_len: 24
frame_interval: 1
max_frame_interval: 20
num_points: 2048
# P4D
radius: 0.7
nsamples: 24
spatial_stride: 32
temporal_kernel_size: 3
temporal_stride: 2
# embedding
emb_relu: false
# transformer
dim: 256
depth: 5
heads: 8
dim_head: 64
mlp_dim: 512
# training
batch_size: 14
epochs: 50
workers: 16
lr: 0.01
momentum: 0.9
weight_decay: 1e-4
lr_milestones:
  - 20
  - 30
lr_gamma: 0.1
lr_warmup_epochs: 10
# output
    # resume
resume: '/caa/Homes01/iballester/dev-svr/p4t-bad/log_zav/BADt1v2_augm/model_49.pth'
start_epoch: 0
    # losses

loss_type: 'weighted_cross_entropy'   # choices=['std_cross_entropy', 'weighted_cross_entropy', 'focal'],
